<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Yuguang Yang</title>
    <link>/</link>
    <description>Recent content on Yuguang Yang</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 03 Jun 2019 12:07:35 -0400</lastBuildDate>
    
	    <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Projects</title>
      <link>/project/</link>
      <pubDate>Mon, 03 Jun 2019 12:07:35 -0400</pubDate>
      
      <guid>/project/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Publications</title>
      <link>/publication/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/publication/</guid>
      <description>&lt;p&gt;Hello World&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/financebook/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/financebook/</guid>
      <description>

&lt;h2 id=&#34;foundations-of-mathematical-finance&#34;&gt;&lt;strong&gt;Foundations of Mathematical Finance&lt;/strong&gt;&lt;/h2&gt;




  

&lt;figure&gt;

&lt;img src=&#34;/img/financebook/financebook.png&#34; /&gt;


&lt;/figure&gt;

&lt;h4 id=&#34;download-this-book&#34;&gt;Download this book&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;/files/financeBook_APR.pdf&#34; target=&#34;_blank&#34;&gt;Download&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;No-Arbitrage Pricing Principle&lt;/li&gt;
&lt;li&gt;Market Instrument, Replication and Models&lt;/li&gt;
&lt;li&gt;Interest Rate Models &amp;amp; Derivatives&lt;/li&gt;
&lt;li&gt;Fixed Income Analytics &amp;amp; Strategies&lt;/li&gt;
&lt;li&gt;Equity Derivatives&lt;/li&gt;
&lt;li&gt;Foreign Exchange Modeling&lt;/li&gt;
&lt;li&gt;Credit Risk Modeling&lt;/li&gt;
&lt;li&gt;Commodity Modeling&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Financial Risk And VaR&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Appendix: Mathematical Facts&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/mathbook/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/mathbook/</guid>
      <description>

&lt;h2 id=&#34;essentials-of-mathematical-methods&#34;&gt;&lt;strong&gt;Essentials of Mathematical Methods&lt;/strong&gt;&lt;/h2&gt;




  

&lt;figure&gt;

&lt;img src=&#34;/img/mathbook/mathbook.PNG&#34; /&gt;


&lt;/figure&gt;

&lt;h4 id=&#34;about-this-book&#34;&gt;About this book&lt;/h4&gt;

&lt;p&gt;Also check out &lt;a href=&#34;https://github.com/yangyutu/EssentialMath&#34; target=&#34;_blank&#34;&gt;github&lt;/a&gt; for updates and issues.&lt;/p&gt;

&lt;h4 id=&#34;download-the-whole-book&#34;&gt;Download the whole book&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;/files/MathBook.pdf&#34; target=&#34;_blank&#34;&gt;Essentials of Mathematical Methods&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&#34;download-selected-topics&#34;&gt;Download selected topics&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;/files/financeBook.pdf&#34; target=&#34;_blank&#34;&gt;Linear Algebra and Matrix Analysis&lt;/a&gt; &lt;br /&gt;
&lt;a href=&#34;/files/financeBook.pdf&#34; target=&#34;_blank&#34;&gt;Linear Regression Analysis&lt;/a&gt; &lt;br /&gt;
&lt;a href=&#34;/files/financeBook.pdf&#34; target=&#34;_blank&#34;&gt;Probability and Statistical Estimation&lt;/a&gt; &lt;br /&gt;
&lt;a href=&#34;/files/financeBook.pdf&#34; target=&#34;_blank&#34;&gt;Markov Chain and Random Walk&lt;/a&gt; &lt;br /&gt;
&lt;a href=&#34;/files/financeBook.pdf&#34; target=&#34;_blank&#34;&gt;Supervised stistical learning&lt;/a&gt; &lt;br /&gt;
&lt;a href=&#34;/files/financeBook.pdf&#34; target=&#34;_blank&#34;&gt;(Deep) Reinforcement Learning&lt;/a&gt; &lt;/p&gt;

&lt;h3 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h3&gt;

&lt;h4 id=&#34;i-mathematical-foundations&#34;&gt;I Mathematical Foundations&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Sets, Sequences and Series&lt;/li&gt;
&lt;li&gt;Metric Space and Topological Space&lt;/li&gt;
&lt;li&gt;Advanced Calculus&lt;/li&gt;
&lt;li&gt;Linear Algebra and Matrix Analysis&lt;/li&gt;
&lt;li&gt;Function Sequences, Series and Approximation&lt;/li&gt;
&lt;li&gt;Basic Functional Analysis&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;ii-mathematical-optimization-methods&#34;&gt;II Mathematical Optimization Methods&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Unconstrained Nonlinear Optimization&lt;/li&gt;
&lt;li&gt;Constrained Nonlinear Optimization&lt;/li&gt;
&lt;li&gt;Linear Optimization&lt;/li&gt;
&lt;li&gt;Convex Analysis and Convex Optimization&lt;/li&gt;
&lt;li&gt;Basic Game Theory&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;iii-classical-statistical-methods&#34;&gt;III Classical Statistical Methods&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Theory of Probability&lt;/li&gt;
&lt;li&gt;Statistical Distributions&lt;/li&gt;
&lt;li&gt;Statistical Estimation Theory&lt;/li&gt;
&lt;li&gt;Multivariate Statistical Methods&lt;/li&gt;
&lt;li&gt;Linear Regression Analysis&lt;/li&gt;
&lt;li&gt;Monte Carlo Methods&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;iv-dynamics-modeling-methods&#34;&gt;IV Dynamics Modeling Methods&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Models and estimation in dynamical systems&lt;/li&gt;
&lt;li&gt;Numerical Differential Equations&lt;/li&gt;
&lt;li&gt;Stochastic Process&lt;/li&gt;
&lt;li&gt;Stochastic Calculus&lt;/li&gt;
&lt;li&gt;Fokker-Planck Equation&lt;/li&gt;
&lt;li&gt;Markov Chain and Random Walk&lt;/li&gt;
&lt;li&gt;Time Series Analysis&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;v-statistical-learning-methods&#34;&gt;V Statistical Learning Methods&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Supervised Learning Principles and Methods&lt;/li&gt;
&lt;li&gt;Linear Models for Regression&lt;/li&gt;
&lt;li&gt;Linear Models for Classification&lt;/li&gt;
&lt;li&gt;Generative Models&lt;/li&gt;
&lt;li&gt;K Nearest Neighbors&lt;/li&gt;
&lt;li&gt;Tree Methods&lt;/li&gt;
&lt;li&gt;Ensemble and Boosting Methods&lt;/li&gt;
&lt;li&gt;Unsupervised Statistical Learning&lt;/li&gt;
&lt;li&gt;Neural Network and Deep Learning&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;vi-optimal-control-and-reinforcement-learning-methods&#34;&gt;VI Optimal Control and Reinforcement Learning Methods&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Classical Optimal Contrl Theory&lt;/li&gt;
&lt;li&gt;Reinforcement Learning&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;appendix-supplemental-mathematical-facts&#34;&gt;Appendix: Supplemental Mathematical Facts&lt;/h4&gt;
</description>
    </item>
    
    <item>
      <title>About Me</title>
      <link>/biosketch/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/biosketch/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;/files/financeBook.pdf&#34; target=&#34;_blank&#34;&gt;Full CV&lt;/a&gt; &lt;/p&gt;

&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;

&lt;p&gt;Artificial intelligence, including machine learning, has emerged as a trending technology that will have
fundamental impact on diverse fields, such as health, finance, robotics and etc. Since my research at
John Hopkins at PhD, I have been exploring the application of AI technology in solving biomedical
challenges - Autonomous navigation of micro-robots in human body. My endeavor in this field
continued after earning PhD degree, through collaboration with John Hopkins and Tsing Hua University.
Link to project movie.&lt;/p&gt;

&lt;h2 id=&#34;at-wells-fargo&#34;&gt;At Wells Fargo&lt;/h2&gt;

&lt;p&gt;I have been working as a quantitative associate at Wells Fargo since July 2017, as I was intrigued by the
elegance and power of mathematical finance. My accomplishment in this field can be found in my
finance book.&lt;/p&gt;

&lt;h2 id=&#34;mathematical-modeling&#34;&gt;Mathematical modeling&lt;/h2&gt;

&lt;p&gt;Applied math is always my passion. I have been taking on various mathematical modeling challenges
since undergrad. I had won top awards in series of most prestigious contests, both internationally and
domestically. My team was Outstanding Winner (ranked top 3 among 2,254 teams) in MCM
(Mathematical Contest in Modeling) of USA in 2010. I also won the First Class Prize in Undergraduate
Mathmatical Contest in Modeling in China and First Class Prize in Advanced Mathematics Contest in
Zhejiang Province in 2008 and 2009, respectively.
My pursuit in applied math and endeavors to thoroughly comprehend mathematical concepts and
modelling tools culminate in the book “Essentials of Mathematical methods”, which consists of more
than 50 chapters (2,000+ pages) surveying major aspects of applied math in science and engineering.
Spanning from/…&lt;/p&gt;

&lt;h2 id=&#34;research&#34;&gt;Research&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>About Me</title>
      <link>/misc/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/misc/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Research</title>
      <link>/research/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/research/</guid>
      <description>

&lt;h2 id=&#34;research-areas&#34;&gt;Research Areas&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#robotAI&#34;&gt;Applied AI Algorithms for Micro/Nano-Robot Systems&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#robotAI-SingleAgent&#34;&gt;Single-agent Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#robotAI-MultiAgent2D&#34;&gt;Multi-agent Systems (2D)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#robotAI-MultiAgent3D&#34;&gt;Multi-agent Systems (3D)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#robotAI-DistributedMultiAgent&#34;&gt;Distributed Multi-agent Systems&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#AIAlgo&#34;&gt;Deep reinforcement learning algorithms&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#StochSystem&#34;&gt;Applied optimal control and estimation in stochastic systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#SimulationAlgo&#34;&gt;Novel simulation algorithms for stochastic physical systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#StochPhysicalSystem&#34;&gt;Modeling stochastic physical systems&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;ai-for-colloidal-robots-a-name-robotai-a&#34;&gt;AI for colloidal robots &lt;a name=&#34;robotAI&#34;&gt;&lt;/a&gt;&lt;/h3&gt;




  

&lt;figure&gt;

&lt;img src=&#34;/img/robot/AIicon2.png&#34; /&gt;


&lt;/figure&gt;

&lt;h4 id=&#34;single-agent-system-a-name-robotai-singleagent-a&#34;&gt;Single-agent System&lt;a name=&#34;robotAI-SingleAgent&#34;&gt;&lt;/a&gt;&lt;/h4&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/b8yFWW_sRZU&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;p&gt;Equipping micro-/nanoscale colloidal robots with artificial intelligence such that they can efficiently navigate in unknown complex environments could dramatically impact their use in emerging applications like precision surgery and targeted drug delivery. Here we develop a model-free deep reinforcement learning algorithm that can train colloidal robots to learn effective navigation strategies in unknown environments with random obstacles. We employed a deep neural network archecture that enables the robot to mimic animal navigation decision-making by directly processing raw sensor input and decomposing long-range navigations to short-range ones. We show that trained robot agents learn to make navigation decisions regarding both obstacle avoidance and travel time minimization, based solely on local sensory inputs without prior knowledge of the global environment. Such agents with biologically inspired mechanisms can acquire competitive navigation capabilities in large-scale, complex environments containing obstacles of diverse shapes, sizes, and configurations. This study illustrates the potential of artificial intelligence to enable colloidal robots in extensive applications.



  

&lt;figure&gt;

&lt;img src=&#34;/img/robot/DRLInterpretation.jpg&#34; /&gt;


&lt;/figure&gt;&lt;/p&gt;

&lt;h4 id=&#34;multi-agent-system-in-2d-a-name-robotai-multiagent2d-a&#34;&gt;Multi-agent System in 2D &lt;a name=&#34;robotAI-MultiAgent2D&#34;&gt;&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;Controlling active colloidal particle swarms could enable useful microscopic functions in emerging applications at the interface of nanotechnology and robotics. Here, we present a computational study of controlling self-propelled colloidal particle propulsion speeds to cooperatively capture and transport cargo particles, which otherwise produce random dispersions. By sensing swarm and cargo coordinates, each particle’s speed is actuated according to a control policy based on multiagent assignment and path planning strategies that navigate stochastic particle trajectories to targets around cargo. Colloidal swarms are shown to dynamically cage cargo at their center via inward radial forces while simultaneously translating via directional forces. Speed, power, and efficiency of swarm tasks display emergent coupled dependences on swarm size and pair interactions and approach asymptotic limits indicating near-optimal performance. This scheme exploits unique interactions and stochastic dynamics in colloidal swarms to capture and transport microscopic cargo in a robust, stable, error-tolerant, and dynamic manner.&lt;/p&gt;




  

&lt;figure&gt;

&lt;img src=&#34;/img/robot/antMultiagent_demo.jpg&#34; /&gt;


&lt;/figure&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/ofibeCz5QM4&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;


&lt;h4 id=&#34;multi-agent-system-in-3d-a-name-robotai-multiagent3d-a&#34;&gt;Multi-agent System in 3D &lt;a name=&#34;robotAI-MultiAgent3D&#34;&gt;&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;Designing intelligent nano-robots that can autonomously navigate in complex and crowded environments such as tissues and blood vessels can offer tremendous possibilities in biomedical applications. Here we report a hierarchical control scheme that enables a nano-robot to efficiently navigate in a blood environment. Our control scheme consists of a high-level controller setting short-ranged dynamic targets to guide the robot to follow a desired path and a low-level deep reinforcement learning controller (DRL) responsible for navigating towards to these dynamic guiding targets. The DRL controller minimally mimics the visual navigation of intelligent species and maps a coarse 3D sensation of the robot’s local environment to control decisions. From extensive navigation data,  the DRL controller is capable of learning competitive, robust, generalizable navigation strategies in free space and in confined environments with red blood cells. Once deployed in blood vessels, the controlled robot can efficiently navigate in blood vessels with different concentrations, vessel size, and RBC configurations. This study identifies the key elements in designing control systems for autonomous nanorobots and illustrates the potential of artificial intelligence for biomedical applications.



  

&lt;figure&gt;

&lt;img src=&#34;/img/robot/robotBloodDemo.jpg&#34; /&gt;


&lt;/figure&gt;&lt;/p&gt;

&lt;h4 id=&#34;distributed-multi-agent-system-a-name-robotai-distributedmultiagent-a&#34;&gt;Distributed Multi-agent System&lt;a name=&#34;robotAI-DistributedMultiAgent&#34;&gt;&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;Assembly large number (&amp;gt;1000) of active colloidal particles into ordered structures can enable applications not attainable in small colloids systems (&amp;lt;100), yet on the other hand poses challenges of developing robust and efficient coordination and control strategies.  Here we report a decentralized and asynchronized control strategy that can enable thousands of active particles to precisely assemble into predefined shapes and perform in-place shape transformations. This is enabled by equipping individual particles with the capability to make decisions on sequential assembly order and navigation through complex environments formed during assembly processes. Using deep reinforcement learning, distributed intelligent particle agents are trained to learn hierarchical navigation strategy across different length scales based on local sensor information at different granularity. Our results demonstrate a flexible and scalable algorithmic framework to control large number of active particles collective assembly behavior in a robust, error-tolerant, reconfigurable and dynamic manner.



  

&lt;figure&gt;

&lt;img src=&#34;/img/robot/LargeScaleRobotAssembly.jpg&#34; /&gt;


&lt;/figure&gt;&lt;/p&gt;

&lt;h3 id=&#34;deep-reinforcement-learning-algorithms-a-name-aialgo-a&#34;&gt;Deep reinforcement learning algorithms&lt;a name=&#34;AIAlgo&#34;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Deep reinforcement learning for high dimensional, hierarchical control tasks usually requires the use of complex neural networks as functional approximators, which can lead to inefficiency, instability and even divergence in the training process. Here, we introduce stacked deep Q learning (SDQL), a flexible modularized deep reinforcement learning architecture, that can enable finding of optimal control policy of control tasks consisting of multiple linear stages in a stable and efficient way. SDQL exploits the linear stage structure by approximating the Q function via a collection of deep Q sub-networks stacking along an axis marking the stage-wise progress of the whole task. By back-propagating the learned state values from later stages to earlier stages, all sub-networks co-adapt to maximize the total reward of the whole task, although each sub-network is responsible for learning optimal control policy for its own stage. This modularized architecture offers considerable flexibility in terms of environment and policy modeling, as it allows choices of different state spaces, action spaces, reward structures, and Q networks for each stage, Further, the backward stage-wise training procedure of SDQL can offers additional transparency, stability, and flexibility to the training process, thus facilitating model fine-tuning and hyper-parameter search. We demonstrate that SDQL is capable of learning competitive strategies for problems with characteristics of high-dimensional state space, heterogeneous action space(both discrete and continuous), multiple scales, and sparse and delayed rewards.



  

&lt;figure&gt;

&lt;img src=&#34;/img/DRLAlgorithms/Architecutre.png&#34; /&gt;


&lt;/figure&gt;&lt;/p&gt;

&lt;h3 id=&#34;applied-optimal-control-and-estimation-in-stochastic-systems-a-name-stochsystem-a&#34;&gt;Applied optimal control and estimation in stochastic systems&lt;a name=&#34;StochSystem&#34;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Perfectly ordered states are targets in diverse molecular to microscale systems involving, for example, atomic clusters, protein folding, protein crystallization, nanoparticle superlattices, and colloidal crystals. However, there is no obvious approach to control the assembly of perfectly ordered global free energy minimum structures; near-equilibrium assembly is impractically slow, and faster out-of-equilibrium processes generally terminate in defective states. Here, we demonstrate the rapid and robust assembly of perfect crystals by navigating kinetic bottlenecks using closed-loop control of electric field mediated crystallization of colloidal particles. An optimal policy is computed with dynamic programming using a reaction coordinate based dynamic model. By tracking real-time stochastic particle configurations and adjusting applied fields via feedback, the evolution of unassembled particles is guided through polycrystalline states into single domain crystals. This approach to controlling the assembly of a target structure is based on general principles that make it applicable to a broad range of processes from nano- to microscales (where tuning a global thermodynamic variable yields temporal control over thermal sampling of different states via their relative free energies).



  

&lt;figure&gt;

&lt;img src=&#34;/img/optimalColloidalAssembly/optimalColloidalAssembly.jpg&#34; /&gt;


&lt;/figure&gt;&lt;/p&gt;

&lt;h3 id=&#34;noval-simulation-algorithms-for-stochastic-physical-systems-a-name-simulationalgo-a&#34;&gt;Noval simulation algorithms for stochastic physical systems&lt;a name=&#34;SimulationAlgo&#34;&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Colloidal rod diffusion near a wall is modeled and simulated based on a constrained Stokesian dynamic model of chains-of-spheres. By modeling colloidal rods as chains-of-spheres, complete diffusion tensors are computed for colloidal rods in bulk media and near interfaces, including hydrodynamic interactions, translation-rotation coupling, and all diffusion modes in the particle and lab frames. Simulated trajectories based on the chain-of-spheres diffusion tensor are quantified in terms of typical experimental quantities such as mean squared positional and angular displacements as well as autocorrelation functions. Theoretical expressions are reported to predict measured average diffusivities as well as the crossover from short-time anisotropic translational diffusion along the rod’s major axis to isotropic diffusion. Diffusion modes are quantified in terms of closed form empirical fits to model results to aid their use in interpretation and prediction of experiments involving colloidal rod diffusion in interfacial and confined systems.&lt;/p&gt;

&lt;p&gt;Brownian dynamics of colloidal particles on complex curved surfaces has found important applications in diverse physical, chemical, and biological processes. However, most Brownian dynamics simulation algorithms focus on relatively simple curved surfaces that can be analytically parameterized. In this work, we develop an algorithm to enable Brownian dynamics simulation on extremely complex curved surfaces. We approximate complex curved surfaces with triangle mesh surfaces and employ a novel scheme to perform particle simulation on these triangle mesh surfaces. Our algorithm computes forces and velocities of particles in global coordinates but updates their positions in local coordinates, which combines the strengths from both global and local simulation schemes. We benchmark the proposed algorithm with theory and then simulate Brownian dynamics of both single and multiple particles on torus and knot surfaces. The results show that our method captures well diffusion, transport, and crystallization of colloidal particles on complex surfaces with nontrivial topology. This study offers an efficient strategy for elucidating the impact of curvature, geometry, and topology on particle dynamics and microstructure formation in complex environments.&lt;/p&gt;




  

&lt;figure&gt;

&lt;img src=&#34;/img/simulation/BrownianManifold.jpg&#34; /&gt;


&lt;/figure&gt;

&lt;h3 id=&#34;modeling-stochastic-physical-systems-a-name-stochphysicalsystem-a&#34;&gt;Modeling stochastic physical systems&lt;a name=&#34;StochPhysicalSystem&#34;&gt;&lt;/a&gt;&lt;/h3&gt;




  

&lt;figure&gt;

&lt;img src=&#34;/img/physicalSystem/physicalSystemModeling.jpg&#34; /&gt;


&lt;/figure&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link></link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid></guid>
      <description></description>
    </item>
    
    <item>
      <title>Posts</title>
      <link>/post/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/post/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Recent &amp; Upcoming Talks</title>
      <link>/talk/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/talk/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
